{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy_cld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import json, spacy\n",
    "import spacy\n",
    "from spacy_cld import LanguageDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAMES = ['figshare', 'hbovpk', 'leraar24', 'stimuleringsmaatregel', 'wur', 'wwmhbo']\n",
    "DATA_ROOT = os.path.join('data', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(collection_name, nlp):\n",
    "    path = os.path.join(DATA_ROOT, collection_name)\n",
    "    currentDirectory = pathlib.Path(path)\n",
    "    items = []\n",
    "# define the pattern\n",
    "    currentPattern = \"l4l*\"\n",
    "    for currentFile in currentDirectory.glob(currentPattern):  \n",
    "        data=load_json_file(currentFile, nlp) \n",
    "    #    data['collection_name'] = collection_name\n",
    "        items.append(data)\n",
    "    return items\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(filename, nlp):\n",
    "    with open(filename) as file:\n",
    "          data = json.load(file)\n",
    "          text = data['documents'][0]['text']\n",
    "          if(text is not None and len(text)>0):\n",
    "              score = language_score(nlp, data['documents'][0]['text'], 'en')\n",
    "          else: \n",
    "              score=0\n",
    "          if (score > 0.80):\n",
    "              data['documents'][0]['language']='en'\n",
    "          else:\n",
    "              data['documents'][0]['language']=None\n",
    "          print('{} \\t {} \\t {}'.format(filename, data['documents'][0]['language'], score)) \n",
    "          data['collection_name']='wur'\n",
    "          return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E090] Extension 'languages' already exists on Doc. To overwrite the existing extension, set `force=True` on `Doc.set_extension`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-22125c8abec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlanguage_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_detector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/spacy_cld/spacy_cld.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, attrs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'languages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'language_scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_languages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mDoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_languages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_languages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mDoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mSpan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_languages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_languages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.set_extension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E090] Extension 'languages' already exists on Doc. To overwrite the existing extension, set `force=True` on `Doc.set_extension`."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "language_detector = LanguageDetector()\n",
    "nlp.add_pipe(language_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output/wur/l4l:wurtv2:dXpITr.json \t en \t 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'l4l:wurtv2:dXpITr',\n",
       " 'url': 'https://wurtv2.wur.nl/p2gplayer/Player.aspx?id=dXpITr',\n",
       " 'keywords': ['anova', 'factorial', 'sums of squares', 'sst'],\n",
       " 'documents': [{'id': '20c4ac016cca7e78073bb68f4f0e573bb773b27f',\n",
       "   'title': 'Factorial ANOVA: SS',\n",
       "   'language': 'en',\n",
       "   'url': 'https://wurtv2.wur.nl/p2gplayer/Player.aspx?id=dXpITr',\n",
       "   'text': \"Hello welcome to the third clip. On for thirty one no fun. Let me show you on a member we are. So we're over here. So after introduction in and clip about. Interaction now we look at. Inference based on some squares. So we once again look at the tomato sweetest example I remember there were two factors. Type of tomato beef share your ground. And there were two ripening generations long or short and the response was the sweetest. Here's a little table with six sample means and. We would like to construct the unknow for table now and for to start with we look at the means model. So we treat these two way. Situation actually as a one way and ofa. And using combined effect to levels. And let's construct you know for table once again. This is just a linear model. So we use Lee's quest to estimate the parameters the perimeter Saddam use. And days. The least ques estimates are very simple just the sample means. And if we don't calculate the sum of the squares of observed mine the sample means we catch the S S E. Everson was Chris or will be in groups or more squares. We would like to compare this full model with. The simplest model. Possible. Containing only. The intercept only Dimmu. Least ques estimate what it knew was just the overall mean so the sum of squares of observed minus the overall mean gives us the S.S.T.. The total sum of squares. And the difference between the two. Is the. Treat and some with squares. Some as quest for treatments or between groups I was quests models of squares. So let's fill be an over table now so here are the crease of freedom we have twelve observations in total for eleven degrees of freedom for total. Twelve minus six year old six degrees of freedom for the winning groups in which squares fly for between. Here is the our code. To give us the. We said you will the air or some such squares for the food. Oh. Four hundred two point two. It goes there. Here we fit. The simplest model possible. That gives us the total so much squares in the difference between the two. Is the models of a square us. OK. So we can of course use the N O function in ours. To get this. An over table they want to go and. Well once again here we have five degrees of freedom because we have six type right. Combinations here. And with the F. test statistic here we can test the new hypothesis whether. There are any differences differences. At all between the six means. The conclusion here is that. There are differences or at least two means are different because the P. value. Is point zero three smaller than the threshold five percent. Now the next question is we know that there are differences. What is causing that is it due to right. To type or. Due to the indirection. So for that we need to effects model and. With the effects model we will try to split the. Treatment somewhat squares into components for the interaction. For the main effect for type arrived. How should we do that. Well. Recall multiple regression. We can compare. Ever since the squares for models with and without the tomb. And we can compare the food and reduce models. We should start with the interaction first. So we compare error some squares for models. With and without. The interaction. So we compared the interaction model but the additive model. And if we do that here we fit a full model and the reduced model for here. If we take the difference. We get the sum was questions you to the interaction twelve point five. In this example. Next we would like to have some so squares for. Main effects of type and of right. But which model should be compare. Well first thing to say is that. We only want to look at main effects if the interaction is an important. If it is removed. So then we compare this additive model where there's no interaction anymore. With this model where the alpha. Parameters are removed. Here it is done in R.. So this is the model. Yet at that model research will somewhat squares this is the model when we leave out type. And the difference between the two. We see just sums of squares give us the sum was quiz for the main effect. Type. And we can do the same for ripe. Now we leave. The B.J. parameters from the edit the model. And the difference now gives. Seventy seven nineteen point nine seven five. Which is that the sum of squares for the main effect of ripe. If we add up the sums as quest for the interaction. For the main effects. We nicely get nine hundred nineteen point eight eight. Which is the same as the treatment was quest that we got in the start at start. OK Well this is quite cumbersome to do it in this way so we also have this a no for function available in our. So if we use an over here. We directly get the sums of squares that we calculated ourselves a minute ago. So this is easier. Of course but you have to realize here that the a no function. Bests we send you some squares of all sequence surely sequence your sums of squares are produced here and they are also called I Want some squares or accumulated sums of squares. Sequential sums of squares and. So what are is doing here it starts with a model with only the intercept. Then it. At Stipe. And it. Reports the difference. If we see do some squares. And then it. At the ripe. And then again it. Reports the difference in recent years some squares between these two models. And it. At the interaction and. We nicely see these jumps which are exactly the same as what we calculated earlier but please realize that for. Time. The model comparison. That is made here for tripe is not the same as what we did earlier. Nevertheless the same squares. Are the same as before. The reason for that is that we have a nice balance situation here with equal numbers of replicas. In all the groups. So the conclusions from the a no for table here. We start with the interaction. So we do the test for interaction. The no hypothesis says that there is no interaction so-L. those interaction parameters are equal to zero. The test that is thick is the mean square of time. By ripe. If either by the M.S.E.E.. It gives outcome point zero zero one three but people you point nine. Larger than five percent. So one clue should is that we do not reject the no hypothesis we do not find any evidence that there is an interaction here between two major types and ripening duration. So the other the model. Actually is good enough. And we continue now with. Test for main effects for time. Therefore ride. So we test the main effect. Of tripe formulated with parameters now using these Alpha asked people these are parameters from the additive model. And the test that they stick is the mean square of type. They're divided by the end as. He deals eight point eight six would be value point zero one six more of the five percent so the conclusion is that you reject the no hypothesis here. And we test the main effect of ripe in the same way and we find once again. A significant. Main effect. Of ripe. OK let's switch to a second example. This is the attention span example that we saw earlier. The response. Why. Now is the attention span of children in minutes. There were two sectors in full fit which class with three levels. A one A two A three and a were two types of commercials. Breakfast cereal commercial in the video game. Commercial was shown. So in this case we have an imbalance this time with an equal numbers of children in disapproves and that is quite important actually. At the bottom here you find a little table with sample meets in the six groups. So let's start again with the means model. We use the I know far function as before. We can test. The no hypothesis whether there are any differences at all. And the conclusion here is that the value is very small that. At least to me is a different in our next question as before is this due to the interaction due to main effect age. Class. And or. The topic of the commercial. So again we would like to split the treatment some squares into components. OK so for that we can use the effects model here. And here is the UNO for table at the bottom that we go on to fill. And for that. We want to compare Simpson squares ever since the squares of certain models. So let's start with the interaction model. Here is the direction model. Here based what we can do in ARC to get the be seducer most quests. And here it goes into the N.L. for table. And this. Interaction model is compared with the simplest model possible. With only demean you is. It is in the model. Called the models called M. five here. So here is what we can do in our to get there we said you so much quest of this model this is the total sum of squares. And here it goes at the bottom. So actually the model sum of squares. Is just the difference between the two. So does this amount that we want to split this amount into different components. So first we want to have some was quest for the interaction. So we leave out the interaction. And we fit the etiquette model. I'm too. Here is what we can do in our we get. And he said you are somewhat square. Yes and if we take the difference between. And one and M. two we could hear the sum of squares for the interaction and. For the main effect. For the main effect of each class. We remove the last parameters from the additive model. So we fit it model and three. Gives us. Every citizen was queso we take the difference between researchers from squares and it brings us this sum of squares. So most quest of age. And in the same way. We can get some more squares for the type of commercial. So this is the way we can build up the N.L. for table. And now. Again. Quite a lot of work. And in the balance case we can use the N O five function though. Will it work here as well. So we can. We can try two different orders actually. So we can use a no for and then put a first in the model then began the interaction. And these are the sums of squares that are is reporting then. But we can also use a different order. B. first then a. And then the interaction. And now please note that. We get different some squares so do. The sum of squares for a if it enters the model first it's not the same as when it enters off the B.. And the same for. Effect to be. For the type of commercial. So be on its own. As the first one will not give the same sort so much quizzes be author a. So we see it as something squares become. Or dependent in the unbalanced case. Put into action. We don't see a difference because in both cases the interaction and this is the last one. So for hypothesis testing it is important that you compared to right models. So for interaction it's clear. We compare the model. With the interaction of any direction mother with the edited model. The main effects. We typically would like to compare them oddly edited model. With a model containing a single term. So we check for the effect of a after correction for B.. And we check for the effect of be off the correction for a. This cannot be obtained with a single call to a no fine R. anymore. The sums are squares that we get but if we use these comparisons are called back to some so squares or partial sums of squares. And please note that here in this and balanced case the type to some squares are not a nice split of the treatment symbol squares. If we add up. These different. Main effects something squares in the interaction sum of squares. We get a number. And some US from this quest which is quite a bit different than the. Treatment I was quest that we got from the. The means model. Besides tied to some sequester also type threesomes or squares. Which differ in which models are being compared. And they used by many. But generally they're not to be preferred. In summary. Means bottle. Yields and I know for table. S. in one way I know for showing the split of total sum of squares into and somewhat squares and ever so much squares and so much Chris can be split. Split into some sort of quest for interaction or for main effects. Some sort of quest for interaction of four main effects are obtained by taking differences of sums. A fair assumption squares of set models by X. clued ing. The term of interest from the model for the balance the signs the split is unique and some squares and not order dependent. For unbalance the signs this political usually not unique. And simpler squares are order dependent. Start have offices testing with Indian. Interaction. And if the interaction is unimportant. And continue with the main effects. And use type two or type to the same so squares. Thanks for attention and see you in the next clip.\\n\",\n",
       "   'mime_type': None}]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_json_file('data/output/wur/l4l:wurtv2:dXpITr.json', nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output/wur/l4l:wurtv2:b00dIP.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c4n4l.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:yYbm8.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d45XlE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bWyyVb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bfi09v.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cRsecD.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:dddzoa.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cBrvGE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bAGWmY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b9xG3l.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dDYf82.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:baGU7J.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ep2MqT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dalR6h.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:tSlp5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:czPXvk.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dDjGPk.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:egxHVd.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dTYCj7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bPh2Qq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dA4AIG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dfRS2X.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dSFF4H.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dRSCAe.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bzOIgj.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cbTVpO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d38Jxz.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bS3Sbf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cAZkGn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:crsKOj.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cyj8AN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dXZxeT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cglIqK.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cVRZhX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ctlDaX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dHpWiN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:KD4Gm.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:YZIdz.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bBW3vr.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:K8qYy.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:POi6O.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dAUfYc.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dwnhWT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:mx8sZ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:diIVbY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dKnugC.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:br0v3X.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dXNm2G.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:I5ZF2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dDPqiB.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:YdIWR.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eJ6Ddm.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ne7xR.json \t en \t 0.98\n",
      "data/output/wur/l4l:wurtv2:bBXBbo.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bY4rpO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b12QYc.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:TT7b7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:CoF8N.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ea9ihO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bEC9ht.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dol5SI.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b2zbup.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cdaU1K.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:xFKmG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c9cURw.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:jJ11C.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:mTrA2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dB4iSW.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cFOdf0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eNDhn1.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dWwPhN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dXpITr.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:kn6HN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:daKDRL.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cT8bwA.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b89xYW.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cNgNde.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dG6ulT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bxv30h.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b0Cd12.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cxe2MO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dIO3oi.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:76JGn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ckBznS.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dU7IqU.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:65sko.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ckv8vS.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:Aju6P.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bedQhD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dup9zb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dbx28q.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b3ioGY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dJbsZK.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cO1qxI.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d4EIYH.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ccIzgl.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b6sgOn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bfdOTU.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cm9GBT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:deLEh4.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cin2dh.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cNUIYp.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dE2RZf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dz7Pq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bV1hUZ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bGvvhu.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dE3cWt.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cjEsLS.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:FQpUi.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cMe0TQ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cTEvwq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bi40iY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bBPLHJ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:chuhPB.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ce0Jhb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bdf1qN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:emrvW3.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:easQQM.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dhW1Ox.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cdS5nb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:e7pXv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:MiljM.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:qkT4d.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dEU1bd.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cYuWxA.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dRAGWe.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bN1kMj.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cbAF8A.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:hJKRA.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:LRJyx.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cf9yYr.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bnWobW.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ejlHbT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dcNAF0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dpK5B2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eP8Z0O.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bvRZ2J.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bZnadl.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d9jZBO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:zAKDP.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:evAKxD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:coTHN4.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b4mCo7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:0zcEX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:OrJv6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c6YaPN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d4LzhZ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:YRsjf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bWhZSD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bYIGOO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dR08OJ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bmxdQW.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d2oPVz.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:P1ZZM.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bzSsp5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dRbkih.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:blad0K.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bhHuD9.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cOf5n8.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cuEArK.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dkixFo.json \t None \t 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output/wur/l4l:wurtv2:dWGSnO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cwGW2e.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cqTeMa.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dgpQVu.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eoCbvh.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d4Mw1f.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eOou0N.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c6mvq6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eb3pH9.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eajNj6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dKe1Zb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dIhLVz.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cyXWmX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c8MJ2V.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b3T38J.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bXb2nM.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eaIVE5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eEP2G5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cvYgmp.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dChVow.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bVuQGO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ea9gk9.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b9odC7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bL8hZq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bAGAMf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bRPNyr.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:5c19G.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:Gjl71.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dxxyGI.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dh50zv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eHkIRX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bz4eI2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dcLNpT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dq1IBv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eoKzQw.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:coHvgL.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:exW8qB.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bnq7E3.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bJYG42.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bCEgA.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bXny2Z.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:KRVR0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ciiSAg.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cWopyY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eexNuI.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:epkVah.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bDgdSO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bhRYkx.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dJDaJi.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:4fRoY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dR4Wk3.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bbiapi.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bayNaH.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cJs0V0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ektkvX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:duEpSS.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:1lH1Z.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:efcNhE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cJQYhw.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b32vBm.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ewAmrW.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:kubW3.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dOL1OU.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cE2ZaD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dPns3.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ekRYPc.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b6Exz7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:yaLKI.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:do9q7w.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cchC1q.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:b36gNO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ZnDg6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dBx8b7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:el917r.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bdGELF.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:euxA8R.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dNbdKK.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:RWDLC.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bY34to.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bKzZS1.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dmGNja.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cInDbu.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cQuyfy.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b6shqI.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dvbko2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dPV2nG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dgppRf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ba5NCD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bdqTfX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cWDr7Q.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:nbVS7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bFtA7y.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d9LghE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:oy4td.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:PYAsu.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bQ3xQG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dNxK2j.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b86Oaa.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bkrbSr.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:AUp62.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dnHW7i.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cUAViz.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eM5gsC.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bts8xq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:chYd5e.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dXDaT3.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c5n9YY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bCs1a5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:mMnhx.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dX52SK.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ctI3aH.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cnayeG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dIcuj2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:btUKeE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cXhyIY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dOFmgH.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:yGk4V.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cCjUsb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bFGZjt.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dg2zhc.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:euB961.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b7ZNV2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:NuSp8.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ektvOZ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:lZDsL.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ddjU02.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dWaQrw.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cZEJWn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bJkx2Z.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bPh3Uq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bNCQXu.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bejDo0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:diaori.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dB8dWL.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:3LRUs.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eaMOSz.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dL0pJN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bZ2iyS.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dH5CTf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bFUAeP.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:OuDJ7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:Swyei.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cWUeTe.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cbMFw2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cYbfih.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bdVsmN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cHktq0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ds8XXT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dA4DsK.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bOCUhv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d6lrdm.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bbnQ5X.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:z6xDR.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bcIDGv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b7QviD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bkMGGA.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c9mhWT.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ZpYJj.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cY6oVv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:debks5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bxrcNb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eNF8kh.json \t en \t 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output/wur/l4l:wurtv2:dWTvNY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cp8BHX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dUzSef.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:DqzIE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bhXrWd.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cWJV8d.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eLLqcU.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dbi5Vi.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cKzThg.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cAzjfb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eM0QoL.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:blOEVn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:9PrMg.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bfMRZ8.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dVxapt.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cEME1L.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:btwA5j.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cumcK5.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bND1wU.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bjpzTM.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dFBA7x.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:evl4Hb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cz5j53.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ezF842.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eIelGl.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eHqcqX.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d1wrEV.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dVxpf0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cf5baO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:izZD7.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:kMVBO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dLjYoG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ci80fq.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dBfDas.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:mMqni.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cYnY2C.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eqbkwQ.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ZU7Hw.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:crd23K.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bpEmMg.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ehIl30.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:1PMIm.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bA2O0M.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cRsTMS.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cY2RyR.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bvGXQh.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cwHtGn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bdsSf9.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:7ple6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cymChC.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cKod0g.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eH0E8X.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cuf8Sx.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:3aGQ0.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b2tW51.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:4AWSr.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eBx34G.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:uING1.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cL0Rwc.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ZrkIy.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ejUBoD.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eenN4Z.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:edyVZf.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eqSOyO.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:V2Iy6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dTR1XU.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:FS4R6.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eITYqN.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bvS9tt.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c9V2Fa.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cof6iE.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dUogAj.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c2K5Ik.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cQnjqn.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:b8c56u.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dfClRo.json \t en \t 0.96\n",
      "data/output/wur/l4l:wurtv2:qxaiY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cudzIk.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eoG2V8.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:0o2xY.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:c9hlIv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:gRXoG.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c45tX3.json \t None \t 0\n",
      "data/output/wur/l4l:wurtv2:wk0wL.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cd43Jk.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:d4G3zY.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ezkKJd.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:c2SiHw.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:y0BZy.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:PqU1G.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:edGWQM.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ccvfgv.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cOcyl9.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:6ZBv2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bybukF.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:cFzqQb.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bVAmBF.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:mqPsA.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dB7k9Q.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:ch8Vmx.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:eCSQn7.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:RK2o2.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bAA7Z8.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:bfwWlx.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dKnzHt.json \t en \t 0.99\n",
      "data/output/wur/l4l:wurtv2:dpNvvi.json \t en \t 0.99\n"
     ]
    }
   ],
   "source": [
    "items = load_data('wur', nlp)\n",
    "with open('my-elasticsearch-documents.json', 'wt') as stream:\n",
    "    json.dump(items, stream, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data('wur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_score(nlp, text, language):\n",
    "    doc = nlp(text)\n",
    "    return doc._.language_scores[language]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_cld import LanguageDetector\n",
    " \n",
    "nlp = spacy.load('en')\n",
    "language_detector = LanguageDetector()\n",
    "nlp.add_pipe(language_detector)\n",
    "doc = nlp('This is some English text.')\n",
    " \n",
    "doc._.languages  # ['en']\n",
    "doc._.language_scores['en']  # 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Now tell me what is this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.language_scores['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
